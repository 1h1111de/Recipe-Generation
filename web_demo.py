import copy
import warnings
import os
import json
from dataclasses import asdict, dataclass
from typing import Callable, List, Optional
import torchvision.transforms as T
from torchvision.transforms.functional import InterpolationMode
import streamlit as st
import torch
from torch import nn
from transformers.generation.utils import LogitsProcessorList, StoppingCriteriaList
from transformers.utils import logging
from transformers import AutoTokenizer, AutoModelForCausalLM
from transformers import AutoModel, AutoTokenizer
from PIL import Image, ImageDraw, ImageFont
from transformers import TextIteratorStreamer
from threading import Thread

# è§£å†³torch.dtype JSONåºåˆ—åŒ–é—®é¢˜çš„å…œåº•é…ç½®
class TorchDtypeEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, torch.dtype):
            return str(obj)
        return super().default(obj)
original_dumps = json.dumps
def custom_dumps(*args, **kwargs):
    kwargs['cls'] = TorchDtypeEncoder
    return original_dumps(*args, **kwargs)
json.dumps = custom_dumps

# æ—¥å¿—åˆå§‹åŒ–
logger = logging.get_logger(__name__)

# é…ç½®é¡¹
MODEL_PATH = "./InternVL2-2B-Receipe1"  # æ¨¡å‹è·¯å¾„
LOGO_PATH = "logo.png"                 # Logoè·¯å¾„
DEFAULT_IMAGE_SIZE = 448               # å›¾åƒé¢„å¤„ç†å°ºå¯¸
DEFAULT_MAX_TILES = 4                  # é»˜è®¤å›¾åƒå—æ•°é‡

# Logoå›¾ç‰‡å…œåº•å¤„ç†
if os.path.exists(LOGO_PATH):
    logo = Image.open(LOGO_PATH)
else:
    logo = Image.new('RGB', (200, 80), color=(240, 240, 240))
    draw = ImageDraw.Draw(logo)
    try:
        font = ImageFont.truetype("/usr/share/fonts/dejavu/DejaVuSans-Bold.ttf", 16)
    except:
        font = ImageFont.load_default()
    draw.text((10, 30), "InternVL2-2B", font=font, fill=(0, 0, 0))

# å›¾åƒé¢„å¤„ç†å¸¸é‡
IMAGENET_MEAN = (0.485, 0.456, 0.406)
IMAGENET_STD = (0.229, 0.224, 0.225)

def build_transform(input_size):
    """æ„å»ºå›¾åƒé¢„å¤„ç†å˜æ¢"""
    MEAN, STD = IMAGENET_MEAN, IMAGENET_STD
    transform = T.Compose([
        T.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),
        T.Resize((input_size, input_size), interpolation=InterpolationMode.BICUBIC),
        T.ToTensor(),
        T.Normalize(mean=MEAN, std=STD)
    ])
    return transform

def find_closest_aspect_ratio(aspect_ratio, target_ratios, width, height, image_size):
    """å¯»æ‰¾æœ€æ¥è¿‘çš„å›¾åƒæ¯”ä¾‹"""
    best_ratio_diff = float('inf')
    best_ratio = (1, 1)
    area = width * height
    for ratio in target_ratios:
        target_aspect_ratio = ratio[0] / ratio[1]
        ratio_diff = abs(aspect_ratio - target_aspect_ratio)
        if ratio_diff < best_ratio_diff:
            best_ratio_diff = ratio_diff
            best_ratio = ratio
        elif ratio_diff == best_ratio_diff:
            if area > 0.5 * image_size * image_size * ratio[0] * ratio[1]:
                best_ratio = ratio
    return best_ratio

def dynamic_preprocess(image, min_num=1, max_num=12, image_size=448, use_thumbnail=False):
    """åŠ¨æ€é¢„å¤„ç†å›¾åƒï¼ˆInternVL2æ ¸å¿ƒé€»è¾‘ï¼‰"""
    orig_width, orig_height = image.size
    aspect_ratio = orig_width / orig_height

    target_ratios = set(
        (i, j) for n in range(min_num, max_num + 1) for i in range(1, n + 1) for j in range(1, n + 1) if
        i * j <= max_num and i * j >= min_num)
    target_ratios = sorted(target_ratios, key=lambda x: x[0] * x[1])

    target_aspect_ratio = find_closest_aspect_ratio(
        aspect_ratio, target_ratios, orig_width, orig_height, image_size)

    target_width = image_size * target_aspect_ratio[0]
    target_height = image_size * target_aspect_ratio[1]
    blocks = target_aspect_ratio[0] * target_aspect_ratio[1]

    resized_img = image.resize((target_width, target_height))
    processed_images = []
    for i in range(blocks):
        box = (
            (i % (target_width // image_size)) * image_size,
            (i // (target_width // image_size)) * image_size,
            ((i % (target_width // image_size)) + 1) * image_size,
            ((i // (target_width // image_size)) + 1) * image_size
        )
        split_img = resized_img.crop(box)
        processed_images.append(split_img)
    assert len(processed_images) == blocks
    if use_thumbnail and len(processed_images) != 1:
        thumbnail_img = image.resize((image_size, image_size))
        processed_images.append(thumbnail_img)
    return processed_images

def load_image(image_file, input_size=448, max_num=12):
    """åŠ è½½å¹¶é¢„å¤„ç†å›¾åƒ"""
    image = Image.open(image_file).convert('RGB')
    transform = build_transform(input_size=input_size)
    images = dynamic_preprocess(image, image_size=input_size, use_thumbnail=True, max_num=max_num)
    pixel_values = [transform(image) for image in images]
    pixel_values = torch.stack(pixel_values)
    return pixel_values

def load_upload_file_and_show(uploaded_file, max_num=DEFAULT_MAX_TILES):
    """å¤„ç†ä¸Šä¼ çš„å›¾ç‰‡å¹¶è¿”å›æ¨¡å‹è¾“å…¥çš„pixel_valuesï¼ˆç»Ÿä¸€float16ç±»å‹ï¼‰"""
    pixel_values = None
    if uploaded_file is not None:
        # æ ¸å¿ƒä¿®å¤ï¼šå¼ é‡ç±»å‹æ”¹ä¸ºfloat16ï¼Œä¸æ¨¡å‹ä¿æŒä¸€è‡´
        pixel_values = load_image(uploaded_file, max_num=max_num).to(torch.float16).cuda()
    return pixel_values

@dataclass
class GenerationConfig:
    """ç”Ÿæˆé…ç½®ç±»"""
    max_length: int = 2048
    top_p: float = 0.75
    temperature: float = 0.1
    do_sample: bool = True
    repetition_penalty: float = 1.000

@torch.inference_mode()
def generate_interactive(
    model,
    tokenizer,
    prompt,
    pixel_values,
    generation_config=None,
):
    """äº¤äº’å¼ç”Ÿæˆå›ç­”ï¼ˆæµå¼è¾“å‡ºï¼Œå»¶é•¿è¶…æ—¶æ—¶é—´ï¼‰"""
    if generation_config is None:
        generation_config = {}
    
    # æ ¸å¿ƒä¿®å¤ï¼šå»¶é•¿streamerè¶…æ—¶æ—¶é—´åˆ°5åˆ†é’Ÿï¼Œé¿å…æ¨ç†è¶…æ—¶
    streamer = TextIteratorStreamer(
        tokenizer, 
        skip_prompt=True, 
        skip_special_tokens=True, 
        timeout=300
    )
    
    # ç”Ÿæˆé…ç½®
    gen_config = dict(
        max_new_tokens=generation_config.get('max_length', 1024),
        do_sample=generation_config.get('do_sample', False),
        temperature=generation_config.get('temperature', 0.1),
        top_p=generation_config.get('top_p', 0.75),
        repetition_penalty=generation_config.get('repetition_penalty', 1.0),
        streamer=streamer,
        pad_token_id=tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id,
        eos_token_id=tokenizer.eos_token_id if tokenizer.eos_token_id is not None else tokenizer.sep_token_id
    )
    
    # å¯åŠ¨çº¿ç¨‹æ‰§è¡Œæ¨¡å‹æ¨ç†
    thread = Thread(target=model.chat, kwargs=dict(
        tokenizer=tokenizer, 
        pixel_values=pixel_values, 
        question=prompt,
        history=None, 
        return_history=False, 
        generation_config=gen_config
    ))
    thread.start()
    
    generated_text = ''
    try:
        for new_text in streamer:
            # æ£€æŸ¥å¯¹è¯ç»“æŸæ ‡è®°
            if hasattr(model, 'conv_template') and new_text == model.conv_template.sep:
                break
            generated_text += new_text
            yield generated_text
    except Exception as e:
        yield f"æµå¼è¾“å‡ºå‡ºé”™ï¼š{str(e)}"

def on_btn_click():
    """æ¸…ç©ºèŠå¤©å†å²çš„å›è°ƒå‡½æ•°"""
    if 'messages' in st.session_state:
        del st.session_state.messages
    if 'pixel_values' in st.session_state:
        st.session_state.pixel_values = None
    if 'uploaded_image' in st.session_state:
        del st.session_state.uploaded_image
    st.session_state.uploader_key += 1

@st.cache_resource
def load_model():
    """åŠ è½½å•æ¨¡å‹ï¼ˆç¼“å­˜èµ„æºï¼Œç»Ÿä¸€float16ç±»å‹ï¼‰"""
    # æ ¸å¿ƒä¿®å¤ï¼šä½¿ç”¨torch_dtypeå‚æ•°ï¼Œæ¨¡å‹ç±»å‹æ”¹ä¸ºfloat16
    model = AutoModel.from_pretrained(
        MODEL_PATH,
        torch_dtype=torch.float16,
        low_cpu_mem_usage=True,
        trust_remote_code=True
    ).eval().cuda()
    
    # å¼ºåˆ¶æ¨¡å‹æ‰€æœ‰å‚æ•°è½¬ä¸ºfloat16ï¼Œé¿å…ç±»å‹æ®‹ç•™
    model = model.to(dtype=torch.float16)
    
    # åŠ è½½åˆ†è¯å™¨
    tokenizer = AutoTokenizer.from_pretrained(
        MODEL_PATH,
        trust_remote_code=True,
        use_fast=False
    )
    return model, tokenizer

def main():
    """ä¸»å‡½æ•°ï¼šæ„å»ºStreamlitç•Œé¢"""
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'uploader_key' not in st.session_state:
        st.session_state.uploader_key = 0
    if 'pixel_values' not in st.session_state:
        st.session_state.pixel_values = None
    if 'uploaded_image' not in st.session_state:
        st.session_state.uploaded_image = None

    # åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
    model, tokenizer = load_model()

    # ä¾§è¾¹æ é…ç½®
    with st.sidebar:
        st.image(logo, caption='InternVL2-2B-Receipe')
        st.divider()
        
        # è¯­è¨€é€‰æ‹©
        lan = st.selectbox(
            '#### ç•Œé¢è¯­è¨€ / Language', 
            ['ä¸­æ–‡', 'English'], 
            help='ä»…åˆ‡æ¢UIæ˜¾ç¤ºè¯­è¨€ / Only switch UI display language'
        )
        
        # é«˜çº§ç”Ÿæˆé€‰é¡¹
        with st.expander('ğŸ”¥ é«˜çº§ç”Ÿæˆé€‰é¡¹ / Advanced Options'):
            temperature = st.slider('æ¸©åº¦ / Temperature', 0.0, 1.0, 0.7, 0.1)
            top_p = st.slider('Top-P', 0.0, 1.0, 0.95, 0.05)
            repetition_penalty = st.slider('é‡å¤æƒ©ç½š / Repetition Penalty', 1.0, 1.5, 1.1, 0.02)
            max_length = st.slider('æœ€å¤§è¾“å‡ºé•¿åº¦ / Max New Tokens', 512, 4096, 1024, 128)
            # æ ¸å¿ƒä¿®å¤ï¼šå‡å°‘å›¾åƒå—æ•°èŒƒå›´ï¼Œé»˜è®¤4
            max_input_tiles = st.slider('å›¾åƒå—æ•° / Max Input Tiles', 1, 8, 4, 1)
        
        # æ¸…ç©ºå†å²æŒ‰é’®
        st.button('æ¸…ç©ºèŠå¤©å†å² / Clear History', on_click=on_btn_click, type='primary')
        st.divider()

        # å›¾ç‰‡ä¸Šä¼ å™¨
        uploaded_image = st.file_uploader(
            'ä¸Šä¼ é£Ÿç‰©å›¾ç‰‡ / Upload Image',
            type=['png', 'jpg', 'jpeg', 'webp'],
            key=f'uploader_{st.session_state.uploader_key}',
            help='ä¸Šä¼ ä½ æƒ³æŸ¥è¯¢çš„é£Ÿç‰©å›¾ç‰‡ï¼Œæ”¯æŒPNG/JPG/WEBPæ ¼å¼' if lan == 'ä¸­æ–‡' else 'Upload food image (PNG/JPG/WEBP)'
        )

        # å¤„ç†ä¸Šä¼ çš„å›¾ç‰‡ï¼ˆä¼ é€’åŠ¨æ€å›¾åƒå—æ•°ï¼‰
        if uploaded_image is not None:
            st.session_state.pixel_values = load_upload_file_and_show(uploaded_image, max_num=max_input_tiles)
            st.session_state.uploaded_image = uploaded_image
            # é¢„è§ˆä¸Šä¼ çš„å›¾ç‰‡
            st.image(uploaded_image, caption='å·²ä¸Šä¼ å›¾ç‰‡ / Uploaded Image', use_column_width=True)

    # ä¸»ç•Œé¢æ ‡é¢˜å’Œæç¤ºè¯­
    if lan == "ä¸­æ–‡":
        st.title('ğŸ² é£Ÿè°±å¤§æ¨¡å‹ - InternVL2-2B')
        sys_prompt = "æ‚¨å¥½ï¼Œæˆ‘æ˜¯é£Ÿè°±å¤§æ¨¡å‹ğŸ²ï¼Œæ‚¨å¯ä»¥ä¸Šä¼ é£Ÿç‰©å›¾ç‰‡å¹¶è¾“å…¥é—®é¢˜ï¼Œæˆ‘ä¼šä¸ºæ‚¨åˆ†æåˆ¶ä½œæ–¹æ³•ï¼"
        chat_placeholder = st.chat_input('è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼ˆå¦‚ï¼šè¿™é“èœæ€ä¹ˆåšï¼Ÿï¼‰...')
    else:
        st.title('ğŸ²  Recipe Generation - InternVL2-2B')
        sys_prompt = "Hello, I am the Cuisine Recipe Model ğŸ². Upload an image and ask a question, I will analyze the making method for you!"
        chat_placeholder = st.chat_input('Type your question (e.g., How to make this dish?)...')

    # åˆå§‹åŒ–èŠå¤©å†å²
    if 'messages' not in st.session_state:
        st.session_state.messages = [{
            'role': 'robot',
            'content': sys_prompt
        }]
    else:
        st.session_state.messages[0]["content"] = sys_prompt

    # ç”Ÿæˆé…ç½®
    generation_config = {
        'max_length': max_length,
        'top_p': top_p,
        'temperature': temperature,
        'do_sample': temperature > 0,
        'repetition_penalty': repetition_penalty
    }

    # å±•ç¤ºèŠå¤©å†å²
    for message in st.session_state.messages:
        with st.chat_message(message['role']):
            st.markdown(message['content'])
            if "image" in message.keys():
                st.image(message['image'], caption='', use_column_width=True)

    # å¤„ç†ç”¨æˆ·æ–‡æœ¬è¾“å…¥
    if chat_placeholder:
        user_prompt = chat_placeholder.strip()
        if not user_prompt:
            st.warning('è¯·è¾“å…¥æœ‰æ•ˆé—®é¢˜ï¼' if lan == 'ä¸­æ–‡' else 'Please enter a valid question!')
            st.stop()

        # æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡
        pixel_values = st.session_state.pixel_values
        if pixel_values is None:
            st.warning('è¯·å…ˆä¸Šä¼ é£Ÿç‰©å›¾ç‰‡ï¼' if lan == 'ä¸­æ–‡' else 'Please upload a food image first!')
            st.stop()

        # å±•ç¤ºç”¨æˆ·æ¶ˆæ¯
        with st.chat_message('user'):
            st.markdown(user_prompt)
            if st.session_state.uploaded_image is not None:
                st.image(st.session_state.uploaded_image, caption='', use_column_width=True)

        # æ„å»ºç”¨æˆ·æ¶ˆæ¯å­—å…¸
        user_message = {'role': 'user', 'content': user_prompt}
        if st.session_state.uploaded_image is not None:
            user_message['image'] = st.session_state.uploaded_image

        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        st.session_state.messages.append(user_message)

        # æ¨¡å‹æ¨ç†å¹¶å±•ç¤ºå›ç­”
        with st.chat_message('robot'):
            message_placeholder = st.empty()
            final_response = ""
            # æµå¼è¾“å‡ºå›ç­”
            try:
                for cur_response in generate_interactive(
                        model=model,
                        tokenizer=tokenizer,
                        prompt=user_prompt,
                        pixel_values=pixel_values,
                        generation_config=generation_config
                ):
                    final_response = cur_response
                    message_placeholder.markdown(final_response + 'â–Œ')
                # æœ€ç»ˆå±•ç¤ºå›ç­”
                message_placeholder.markdown(final_response)
            except Exception as e:
                error_msg = f"ç”Ÿæˆå›ç­”æ—¶å‡ºé”™: {str(e)}" if lan == 'ä¸­æ–‡' else f"Error generating response: {str(e)}"
                st.error(error_msg)
                final_response = error_msg

        # æ·»åŠ æœºå™¨äººæ¶ˆæ¯åˆ°å†å²
        st.session_state.messages.append({
            'role': 'robot',
            'content': final_response
        })

if __name__ == '__main__':
    # è®¾ç½®é¡µé¢é…ç½®
    st.set_page_config(
        page_title='é£Ÿè°±å¤§æ¨¡å‹-InternVL2-2B',
        page_icon='ğŸ²',
        layout='wide'
    )
    # ç¦ç”¨PyTorchçš„CUDAå†…å­˜åˆ†é…è­¦å‘Šï¼ˆå¯é€‰ï¼‰
    torch.cuda.empty_cache()
    main()